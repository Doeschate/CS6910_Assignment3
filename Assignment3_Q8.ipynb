{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"7m0rEjp7Ex4G","execution":{"iopub.status.busy":"2022-05-07T20:23:57.567763Z","iopub.execute_input":"2022-05-07T20:23:57.568264Z","iopub.status.idle":"2022-05-07T20:24:07.998403Z","shell.execute_reply.started":"2022-05-07T20:23:57.568172Z","shell.execute_reply":"2022-05-07T20:24:07.997549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\nfrom tqdm import tqdm, trange\nimport torch.nn.functional as F\nimport csv","metadata":{"id":"BvAEHzZ5c3_1","execution":{"iopub.status.busy":"2022-05-07T20:24:26.914416Z","iopub.execute_input":"2022-05-07T20:24:26.915009Z","iopub.status.idle":"2022-05-07T20:24:33.042011Z","shell.execute_reply.started":"2022-05-07T20:24:26.914967Z","shell.execute_reply":"2022-05-07T20:24:33.040985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GPT2 with Fine Tuning","metadata":{"id":"Yd7iKbfRPNXs"}},{"cell_type":"markdown","source":"### Prepare data","metadata":{"id":"ugqA8sTyorE7"}},{"cell_type":"code","source":"lyrics = pd.read_csv('../input/scrapped-lyrics-from-6-genres/lyrics-data.csv')\nlyrics = lyrics[lyrics['language']=='en']","metadata":{"id":"VA0fsB0kkO3P","execution":{"iopub.status.busy":"2022-05-07T20:24:54.185797Z","iopub.execute_input":"2022-05-07T20:24:54.186072Z","iopub.status.idle":"2022-05-07T20:25:03.829697Z","shell.execute_reply.started":"2022-05-07T20:24:54.186042Z","shell.execute_reply":"2022-05-07T20:25:03.828892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = lyrics\ndf.drop(df.columns.difference(['Lyric']), 1, inplace=True)\ndf = df[df['Lyric'].apply(lambda x: len(x.split(' ')) < 350)]","metadata":{"execution":{"iopub.status.busy":"2022-05-07T20:25:19.940051Z","iopub.execute_input":"2022-05-07T20:25:19.940333Z","iopub.status.idle":"2022-05-07T20:25:22.090531Z","shell.execute_reply.started":"2022-05-07T20:25:19.940302Z","shell.execute_reply":"2022-05-07T20:25:22.089768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the dataset","metadata":{"id":"gqNpDGm_JnFk"}},{"cell_type":"code","source":"class SongLyrics(Dataset):\n    \n    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n\n        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n        self.lyrics = []\n\n        for row in df['Lyric']:\n            self.lyrics.append(torch.tensor(\n                self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n            ))\n                \n        if truncate:\n            self.lyrics = self.lyrics[:20000]\n        self.lyrics_count = len(self.lyrics)\n        \n    def __len__(self):\n        return self.lyrics_count\n\n    def __getitem__(self, item):\n        return self.lyrics[item]","metadata":{"id":"V71yg83t6Tlt","execution":{"iopub.status.busy":"2022-05-07T20:25:31.113163Z","iopub.execute_input":"2022-05-07T20:25:31.11345Z","iopub.status.idle":"2022-05-07T20:25:31.121377Z","shell.execute_reply.started":"2022-05-07T20:25:31.113418Z","shell.execute_reply":"2022-05-07T20:25:31.120684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = SongLyrics(df['Lyric'],truncate=True, gpt2_type=\"gpt2\")","metadata":{"id":"wauU2WYi92dp","execution":{"iopub.status.busy":"2022-05-07T20:26:08.727037Z","iopub.execute_input":"2022-05-07T20:26:08.727347Z","iopub.status.idle":"2022-05-07T20:38:28.664126Z","shell.execute_reply.started":"2022-05-07T20:26:08.727313Z","shell.execute_reply":"2022-05-07T20:38:28.663337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare training","metadata":{"id":"MwIRpL_5MnIY"}},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"id":"3fPgwmaNFTib","execution":{"iopub.status.busy":"2022-05-07T20:39:48.129283Z","iopub.execute_input":"2022-05-07T20:39:48.129587Z","iopub.status.idle":"2022-05-07T20:40:09.354921Z","shell.execute_reply.started":"2022-05-07T20:39:48.129551Z","shell.execute_reply":"2022-05-07T20:40:09.354171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accumulated batch size (since GPT2 is so big)\ndef pack_tensor(new_tensor, packed_tensor, max_seq_len):\n    if packed_tensor is None:\n        return new_tensor, True, None\n    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n        return packed_tensor, False, new_tensor\n    else:\n        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n        return packed_tensor, True, None","metadata":{"id":"Maf_wuBuJl2n","execution":{"iopub.status.busy":"2022-05-07T20:40:16.403559Z","iopub.execute_input":"2022-05-07T20:40:16.40382Z","iopub.status.idle":"2022-05-07T20:40:16.411765Z","shell.execute_reply.started":"2022-05-07T20:40:16.403793Z","shell.execute_reply":"2022-05-07T20:40:16.410959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n    dataset, model, tokenizer,\n    batch_size=64, epochs=10, lr=0.002,\n    max_seq_len=400, warmup_steps=200,\n    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n    test_mode=False,save_model_on_epoch=False,\n):\n\n    acc_steps = 100\n#     device=torch.device(\"cpu\")\n\n    device=torch.device(\"cuda\")\n    model = model.cuda()\n    model.train()\n\n    optimizer = AdamW(model.parameters(), lr=lr)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n    )\n\n    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n    loss=0\n    accumulating_batch_count = 0\n    input_tensor = None\n\n    for epoch in range(epochs):\n\n        print(f\"Training epoch {epoch}\")\n        print(loss)\n        for idx, entry in tqdm(enumerate(train_dataloader)):\n            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n\n            if carry_on and idx != len(train_dataloader) - 1:\n                continue\n\n            input_tensor = input_tensor.to(device)\n            outputs = model(input_tensor, labels=input_tensor)\n            loss = outputs[0]\n            loss.backward()\n\n            if (accumulating_batch_count % batch_size) == 0:\n                optimizer.step()\n                scheduler.step()\n                optimizer.zero_grad()\n                model.zero_grad()\n\n            accumulating_batch_count += 1\n            input_tensor = None\n        if save_model_on_epoch:\n            torch.save(\n                model.state_dict(),\n                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n            )\n    return model","metadata":{"id":"65ZWYy8EJl0D","execution":{"iopub.status.busy":"2022-05-07T20:40:28.904269Z","iopub.execute_input":"2022-05-07T20:40:28.904556Z","iopub.status.idle":"2022-05-07T20:40:28.918427Z","shell.execute_reply.started":"2022-05-07T20:40:28.904517Z","shell.execute_reply":"2022-05-07T20:40:28.917706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Actual Training","metadata":{"id":"LIXXMDBONZtR"}},{"cell_type":"code","source":"#Train the model on the specific data we have\nmodel = train(dataset, model, tokenizer)","metadata":{"id":"qY7dh37IvscH","outputId":"521d618e-e69b-4e65-a1b5-eeef06ca4134","execution":{"iopub.status.busy":"2022-05-07T20:40:33.358394Z","iopub.execute_input":"2022-05-07T20:40:33.359007Z","iopub.status.idle":"2022-05-07T23:29:11.931975Z","shell.execute_reply.started":"2022-05-07T20:40:33.358964Z","shell.execute_reply":"2022-05-07T23:29:11.931178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save the model to a pkl or something so it can be reused later on\ntorch.save(model, './model.pt')\n#Load the model to use it\nmodel = torch.load('./model.pt')","metadata":{"id":"gvk9JcukKKq1","execution":{"iopub.status.busy":"2022-05-07T23:30:10.402427Z","iopub.execute_input":"2022-05-07T23:30:10.404781Z","iopub.status.idle":"2022-05-07T23:30:11.418045Z","shell.execute_reply.started":"2022-05-07T23:30:10.404741Z","shell.execute_reply":"2022-05-07T23:30:11.417322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Text generation","metadata":{"id":"9BlNPVfXPNQf"}},{"cell_type":"code","source":"def generate(\n    model,\n    tokenizer,\n    prompt,\n    entry_count=10,\n    entry_length=300, #maximum number of words\n    top_p=0.8,\n    temperature=1.,\n):\n\n    model.eval()\n\n    generated_num = 0\n    generated_list = []\n\n    filter_value = -float(\"Inf\")\n\n    with torch.no_grad():\n\n        for entry_idx in trange(entry_count):\n\n            entry_finished = False\n\n            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n\n            for i in range(entry_length):\n                outputs = model(generated, labels=generated)\n                loss, logits = outputs[:2]\n                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n\n                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n\n                sorted_indices_to_remove = cumulative_probs > top_p\n                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n                sorted_indices_to_remove[..., 0] = 0\n\n                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n                logits[:, indices_to_remove] = filter_value\n\n                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n                generated = torch.cat((generated, next_token), dim=1)\n\n                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n                    entry_finished = True\n\n                if entry_finished:\n\n                    generated_num = generated_num + 1\n\n                    output_list = list(generated.squeeze().numpy())\n                    output_text = tokenizer.decode(output_list)\n                    generated_list.append(output_text)\n                    break\n            \n            if not entry_finished:\n                output_list = list(generated.squeeze().numpy())\n                output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n                generated_list.append(output_text)\n                \n    return generated_list","metadata":{"id":"MQUN1Da2JluS","execution":{"iopub.status.busy":"2022-05-07T23:29:11.933906Z","iopub.execute_input":"2022-05-07T23:29:11.934288Z","iopub.status.idle":"2022-05-07T23:29:11.947531Z","shell.execute_reply.started":"2022-05-07T23:29:11.934249Z","shell.execute_reply":"2022-05-07T23:29:11.946864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set = \"I Love Deep Learning\"\nx = generate(model.to('cpu'), tokenizer, test_set, entry_count=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T23:29:11.948443Z","iopub.execute_input":"2022-05-07T23:29:11.948787Z","iopub.status.idle":"2022-05-07T23:30:10.369345Z","shell.execute_reply.started":"2022-05-07T23:29:11.948746Z","shell.execute_reply":"2022-05-07T23:30:10.368244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"execution":{"iopub.status.busy":"2022-05-07T23:30:10.37136Z","iopub.execute_input":"2022-05-07T23:30:10.3717Z","iopub.status.idle":"2022-05-07T23:30:10.378242Z","shell.execute_reply.started":"2022-05-07T23:30:10.371662Z","shell.execute_reply":"2022-05-07T23:30:10.37756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=x[0].split()[:-1]\nb = ' '.join(a)","metadata":{"execution":{"iopub.status.busy":"2022-05-07T23:30:10.379732Z","iopub.execute_input":"2022-05-07T23:30:10.380213Z","iopub.status.idle":"2022-05-07T23:30:10.38907Z","shell.execute_reply.started":"2022-05-07T23:30:10.380165Z","shell.execute_reply":"2022-05-07T23:30:10.3881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b","metadata":{"execution":{"iopub.status.busy":"2022-05-07T23:30:10.390072Z","iopub.execute_input":"2022-05-07T23:30:10.391632Z","iopub.status.idle":"2022-05-07T23:30:10.401485Z","shell.execute_reply.started":"2022-05-07T23:30:10.391593Z","shell.execute_reply":"2022-05-07T23:30:10.400781Z"},"trusted":true},"execution_count":null,"outputs":[]}]}